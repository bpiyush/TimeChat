{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6b0386-8534-4d32-b61f-807a8eaf839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9977e4-ba59-499d-ab04-927e092f2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9816ab2a-20be-4679-862a-3dc3e03f1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_api import (\n",
    "    # load_config,\n",
    "    load_model, setup_seeds, ask_about_video,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dde0ca2-58ee-47da-a42a-98cad76891d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chat\n",
      "Loading VIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:freeze vision encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "use text input for Qformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load checkpoint from /work/piyush/pretrained_checkpoints/LargeModels/TimeChat/instruct_blip_vicuna7b_trimmed.pth\n",
      "INFO:root:freeze Qformer\n",
      "INFO:root:Loading Q-Former Done\n",
      "INFO:root:Loading LLAMA Tokenizer\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Using pad_token, but it is not set yet.\n",
      "INFO:root:Loading LLAMA Model\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:27<00:00, 13.53s/it]\n",
      "INFO:root:use gradient checkpointing for LLAMA\n",
      "INFO:root:Loading LLAMA Done\n",
      "INFO:root:Using LORA (lora_alpha=32)\n",
      "INFO:root:Loading LLAMA proj\n",
      "INFO:root:LLAMA proj is frozen\n",
      "INFO:root:Loading llama_proj Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 6,771,970,048 || trainable%: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:video_Qformer is frozen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load first Checkpoint: /work/piyush/pretrained_checkpoints/LargeModels/TimeChat//TimeChat-7b/timechat_7b.pth\n",
      "Initialization Finished\n"
     ]
    }
   ],
   "source": [
    "model, vis_processor, args, chat = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e58d8-9bab-4725-b4bc-2288d201bc82",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cbc1aa-ae5d-4fb9-8117-f24787360e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing all videos\n",
    "video_dir = \"/scratch/shared/nfs2/piyush/datasets/ViLMA/videos\"\n",
    "\n",
    "# Directory containing metadata\n",
    "metad_dir = \"/users/piyush/projects/ViLMA/data\"\n",
    "\n",
    "\n",
    "def load_json(path: str) -> dict:\n",
    "    \"\"\"Helper to load json file\"\"\"\n",
    "    import json\n",
    "    with open(path, 'rb') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0459bce-8109-4669-b2ca-3818f1507ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_task = \"change-state\"\n",
    "sub_task = \"action\"\n",
    "task_file = os.path.join(\n",
    "    metad_dir, f\"{main_task}-{sub_task}.json\"\n",
    ")\n",
    "assert os.path.join(task_file)\n",
    "task_data = load_json(task_file)\n",
    "len(task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08fa436-3174-42c0-94c0-7035347e6b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(task_data).T\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b04684a7-1fcf-4eec-96d9-0ce7e198455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 19), 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add video ID to each row\n",
    "\n",
    "def get_video_id(item):\n",
    "    from_yt = ['RareAct', 'VidSitu', 'youcook2', 'coin']\n",
    "    # find the full path\n",
    "    dataset = item['dataset']\n",
    "    video_file = item['video_file']\n",
    "    # video_path = None\n",
    "    if dataset == 'QUVA':\n",
    "        normalized = item.get('normalized')\n",
    "        assert normalized\n",
    "        # video_dir = osp.join(self.quva_dir, 'normalized_videos')\n",
    "        # video_path = osp.join(video_dir, video_file)\n",
    "        video_id = video_file\n",
    "    elif dataset == 'something-something-v2':\n",
    "        # video_dir = self.something_something_dir\n",
    "        # video_path = osp.join(video_dir, f'{item[\"dataset_idx\"]}.webm')\n",
    "        video_id = item[\"dataset_idx\"]\n",
    "    elif dataset == 'star':\n",
    "        # video_dir = self.star_dir\n",
    "        # video_path = osp.join(video_dir, f\"{video_file}.mp4\")\n",
    "        video_id = video_file\n",
    "    elif dataset in from_yt:\n",
    "        # video_dir = self.youtube_dir\n",
    "        # video_path = osp.join(video_dir, f'{item[\"youtube_id\"]}.mp4')\n",
    "        video_id = item[\"youtube_id\"]\n",
    "    else:\n",
    "        raise NotImplementedError('Not implemented yet.')\n",
    "    return video_id\n",
    "\n",
    "video_ids = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].to_dict()\n",
    "    video_id = get_video_id(row)\n",
    "    video_ids.append(video_id)\n",
    "df[\"video_id\"] = video_ids\n",
    "\n",
    "df.shape, df.video_id.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ac8157-9f57-4cee-b9e0-b920f57433fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((624, 20), 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_video_path(video_dir, video_id):\n",
    "    paths = glob(os.path.join(video_dir, f\"{video_id}.*\"))\n",
    "    assert len(paths) in [0, 1]\n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        path = paths[0]\n",
    "        return path\n",
    "\n",
    "\n",
    "df[\"video_path\"] = df[\"video_id\"].apply(\n",
    "    lambda x: search_video_path(video_dir, x)\n",
    ")\n",
    "df.shape, df.video_path.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9cba3a4-0ed8-4356-bd90-69e48bf10129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = df[df.video_path.apply(lambda x: os.path.exists(x) if x is not None else False)].copy()\n",
    "subdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6de2259-8478-4d88-8cd0-f5185bdcc668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given query happens in 567, 1135, 2271, 3406, and 3974 frames.\n"
     ]
    }
   ],
   "source": [
    "# Test on a sample row\n",
    "i = 0\n",
    "row = subdf.iloc[i].to_dict()\n",
    "video_path = row[\"video_path\"]\n",
    "\n",
    "caption = row[\"caption\"].lower()\n",
    "foil = row[\"foils\"][0].lower()\n",
    "\n",
    "randomise_options = True\n",
    "enum_options = [\"(a)\", \"(b)\"]\n",
    "if randomise_options:\n",
    "    if np.random.uniform() < 0.5:\n",
    "        text_options = [caption, foil]\n",
    "        correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "    else:\n",
    "        text_options = [foil, caption]\n",
    "        correct_answer = f\"{enum_options[1]} {caption}\"\n",
    "user_message = \"Given this video, you have to select which is the option \"\\\n",
    "    \"that correctly describes the video: \"\\\n",
    "    f\"{enum_options[0]} {text_options[0]} \"\\\n",
    "    f\"{enum_options[1]} {text_options[1]} \"\\\n",
    "    f\"You have to only answer {enum_options[0]} or {enum_options[0]}.\"\n",
    "\n",
    "model_answer = ask_about_video(chat, video_path, user_message)\n",
    "print(model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e559ac-2c10-4db1-8458-abb95f5887ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answer in model_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1162d23c-720e-48a7-af1a-f582c7340750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_row(row, verbose=False, randomise_options=True, enum_options=[\"(a)\", \"(b)\"]):\n",
    "    \"\"\"Checks a single row.\"\"\"\n",
    "\n",
    "    video_path = row[\"video_path\"]    \n",
    "    caption = row[\"caption\"].lower()\n",
    "    foil = row[\"foils\"][0].lower()\n",
    "    \n",
    "    if randomise_options:\n",
    "        if np.random.uniform() < 0.5:\n",
    "            text_options = [caption, foil]\n",
    "            correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "        else:\n",
    "            text_options = [foil, caption]\n",
    "            correct_answer = f\"{enum_options[1]} {caption}\"\n",
    "    else:\n",
    "        text_options = [caption, foil]\n",
    "        correct_answer = f\"{enum_options[0]} {caption}\"\n",
    "\n",
    "    user_message = \"Given this video, you have to select which is the option \"\\\n",
    "        \"that correctly describes the video: \"\\\n",
    "        f\"{enum_options[0]} {text_options[0]} \"\\\n",
    "        f\"{enum_options[1]} {text_options[1]} \"\\\n",
    "        f\"You have to only answer {enum_options[0]} or {enum_options[0]}.\"\n",
    "    \n",
    "    model_answer = ask_about_video(chat, video_path, user_message)\n",
    "    flag = correct_answer in model_answer\n",
    "\n",
    "    if verbose:\n",
    "        print(\"QUESTION: \", user_message)\n",
    "        print(\"VIDEO: \", video_path)\n",
    "        print(\"MODEL ANSWER: \", model_answer)\n",
    "        print(\"IDEAL ANSWER: \", correct_answer)\n",
    "\n",
    "    return flag\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def tqdm_iterator(items, desc=None, bar_format=None, **kwargs):\n",
    "    tqdm._instances.clear()\n",
    "    iterator = tqdm(\n",
    "        items,\n",
    "        desc=desc,\n",
    "        bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',\n",
    "        **kwargs,\n",
    "    )\n",
    "    tqdm._instances.clear()\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec83b19-c934-4a1d-baa7-9bee83984d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on entire dataset:   1%|          | 5/618 [01:15<1:48:57, 10.67s/it]                                                                                                   "
     ]
    }
   ],
   "source": [
    "iterator = tqdm_iterator(range(len(subdf)), desc=\"Evaluating on entire dataset\")\n",
    "randomised_flags = []\n",
    "nonrandomised_flags = []\n",
    "failed = []\n",
    "for i in iterator:\n",
    "    row = subdf.iloc[i].to_dict()\n",
    "    try:\n",
    "        flag = check_row(row, verbose=False, randomise_options=True)\n",
    "        flag_ = check_row(row, verbose=False, randomise_options=False)\n",
    "    except:\n",
    "        # Failed on this video\n",
    "        failed.append(i)\n",
    "    randomised_flags.append(flag)\n",
    "    nonrandomised_flags.append(flag_)\n",
    "    # break\n",
    "randomised_flags = np.array(randomised_flags).astype(int)\n",
    "nonrandomised_flags = np.array(nonrandomised_flags).astype(int)\n",
    "print(\"Accuracy (with randomised options): \", np.mean(randomised_flags))\n",
    "print(\"Accuracy (without randomised options): \", np.mean(nonrandomised_flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7332c9f4-b472-4fb2-9b31-4333b7968fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (with randomised options):  0.2313915857605178\n",
      "Accuracy (without randomised options):  0.42394822006472493\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (with randomised options): \", np.mean(randomised_flags))\n",
    "print(\"Accuracy (without randomised options): \", np.mean(nonrandomised_flags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b9637-cc35-4193-b6f1-e93517ea1b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
